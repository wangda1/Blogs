---
title: 事件抽取
date: 2019-12-10 18:14:17
categories:
- NLP
- 事件抽取
tags:
- NLP
- 事件抽取
---


## 事件抽取综述

*参考：*

- [topin27的github：关于时间抽取的论文综述](http://topin27.github.io/papers/NLP.html#todo-joint-event-extraction-via-recurrent-neural-networks)
### 1. 事件

#### 1.1 定义

> 在TDT（Topic Detection Tracking）中，事件是指关于某一具体主题的一组相关描述，这个主题可以是由分类或聚类完成的

#### 1.2 组成元素

组成事件的各元素包括：触发词、事件类型、论元及论元角色

- 事件触发词：表示事件发生的核心词，多为动词和名词；
- 事件类型：ACE2005定义了8种事件类型和33种子类型
- 事件论元：事件的参与者，主要由实体、值和时间构成。值时一种非实体的参与者，例如：工作岗位等
- 论元角色：事件论元在事件中充当的角色。

ACE2005定义了8种事件类型和33种子类型，35类角色类型。将事件抽取任务转化为基于这些模板的多元分类任务。

### 2. 事件抽取技术

目前的事件抽取任务多为分类任务：可分解为4个子任务：触发词识别、事件类型分类、论元识别和角色分类。

- 事件识别任务： 触发词识别和事件类型分类
- 论元角色识别： 论元识别和角色分类

目前原事件抽取的技术主要有：模式匹配和机器学习两个大类

#### 2.1 模式匹配

模式匹配是在一些模式的指导下进行事件的抽取和识别。抽取时只要通过各种模式匹配算法找出符合模式约束条件信息即可。其核心是抽取模式的构建。但其限定于特定领域在其中拥有较好的效果，并且模式的创建费时费力。典型的基于模式匹配的事件抽取系统有：ExDisco、GenPAM 等。

#### 2.2 机器学习

使用机器学习的方法进行事件抽取作为一种多元分类的任务，事件抽取方法包括 特征选择 和 分类模型

- 特征选择：根据所使用特征的方法分为：句子级的事件抽取和篇章级的事件抽取
- 学习方式：分为基于流水线模型的事件抽取方法和基于联合模型的事件抽取方法

#### 2.3 评价指标

对于事件提取的结果的评测一般采用MUC会议的评测标准，包括三个指标：正确率P、召回率R和F值：

> 正确率：提取出的正确信息条数 / 提取出的信息条数
> 召回率：提取出的正确信息条数 / 样本的信息条数
> F-Measure：是Precision和Recall的加权调和平均

### 3. 相关博客阅读

#### 3.1 Natural Language Processing — Event Extraction (Extracting events from news articles)

原文链接：https://towardsdatascience.com/natural-language-processing-event-extraction-f20d634661d3

- 数据源：从 newsapi 调用获得
- 表示：使用了 SpaCy 预训练模型，SpaCy 也是 BoW 模型（这篇文章还介绍了 Sent2Vec， SkipThoughts等）
- 聚类算法：DBSCAN 不需要设置 cluster 的数量
- 选取 cluster 最中心的作为代表性语句（时间线根据新闻发布时间为时间线）

最后，作者提出的一些改进思路为：合适地进行数据预处理、包括词性标注、NER等应用较好的向量模型等

### 4. 相关软件包

Stanford CoreNLP 是 Stanford 大学自然语言处理小组用 Java 实现的，提供了 Server方式进行交互，使用 `Stanford CoreNLP server`的 packages 有：

- `stanfordcorenlp`. A python wrapper to Stanford CoreNLP server.

    使用该方式需要下载 Java version Stanford CoreNLP package，并通过该 Python wrapper 调用它

Stanford官方发布了Python版本的NLP处理工具，该工具不再依赖于Java

- `stanfordnlp`

### 参考

1. https://blog.csdn.net/qq_35203425/article/details/80451243
2. [徐阿衡](http://www.shuang0420.com/2018/10/15/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/)
3. 

