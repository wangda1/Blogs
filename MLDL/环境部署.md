---
title: 环境部署
date: 2019-11-26 16:58:09
categories:
- MLDL
tags:
- MLDL
---

# 深度学习环境的部署

## 0. 查看GPU环境

- 查看 GPU 型号： `lspci | grep -i nvidia`
- 查看 GPU 驱动版本： `sudo dpkg --list | grep nvidia-*`

## 1. CUDA 环境的配置

refer:   
    1. https://www.cnblogs.com/yhjoker/p/10972795.html  
    2. https://blog.csdn.net/wanzhen4330/article/details/81699769#cudnn%E7%9A%84%E5%AE%89%E8%A3%85

- 如何更改 `cuda` 版本

先来看下 pytorch 如何找到 cuda（以下过程为顺序进行，满足条件即停止）

1. 先查看环境变量 `CUDA_HOME` 或 `CUDA_PATH`
2. 检查系统固定路径 `/usr/local/cuda`，寻找该软链接文件
3. `which nvcc` 查看 `nvcc` 所在的 cuda 安装目录，并将其作为运行时的 cuda 版本

通过以上可以确定更改 `cuda` 的方法：

1. 对于非 `root` 账户，可以使用环境变量的方法：指定 `CUDA_HOME` 与 `PATH`
2. 对于 `root` 账户，可以在 `/usr/local/cuda` 修改该软链接文件

- 如何查看 `cuda` 及 `cudnn` 版本

```python
>>> import torch
>>> torch.version.cuda   # 该命令查看的是编译 pytorch 使用的 cuda 版本，并不一定是运行的时候的版本
```

```python
>>> import torch
>>> import torch.utils
>>> import torch.utils.cpp_extension
>>> torch.utils.cpp_extension.CUDA_HOME # 此为查看运行时的 cuda 版本的方法
```

或者通过查看 `/usr/local/cuda` 目录：

```shell
# cuda 版本
cat /usr/local/cuda/version.txt
# cudnn 版本
cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
nvcc --version
```

## 2. cudnn 的安装

cudnn 是用于深度神经网络加速的GPU加速库，可以集成到更高级别的机器学习框架中，如 caffe。相比于标准的 cuda，它在一些常用的神经网络操作上进行了性能的优化。

它的安装只需要将 package 下载下来，解压到 CUDA_HOME 中的 `include`、`lib`、`bin` 目录下即可。

- `cudnn` 版本的查看

    `cat $CUDA_HOME/include/cudnn.h | grep CUDNN_MAJOR -A 2`

```shell
# !/bin/bash

# Install CUDA Toolkit v8.0 and cudnn v6.0 on ubuntu 16.04
# instructions from https://developer.nvidia.com/cuda-downloads (linux -> x86_64 -> Ubuntu -> 16.04 -> deb (network))
CUDA_REPO_PKG="cuda-repo-ubuntu1604_8.0.61-1_amd64.deb"
wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/${CUDA_REPO_PKG}
sudo dpkg -i ${CUDA_REPO_PKG}
sudo apt-get update
sudo apt-get -y install cuda

# install cuDNN v6.0
CUDNN_TAR_FILE="cudnn-8.0-linux-x64-v6.0.tgz"
wget http://developer.download.nvidia.com/compute/redist/cudnn/v6.0/${CUDNN_TAR_FILE}
tar -xzvf ${CUDNN_TAR_FILE}
sudo cp -P cuda/include/cudnn.h /usr/local/cuda-8.0/include
sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-8.0/lib64/
sudo chmod a+r /usr/local/cuda-8.0/include/cudnn.h /usr/local/cuda-8.0/lib64/libcudnn*

# set environment variables
export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64\${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
```

## 3. pytorch 中查看GPU信息

```python
# cuda 是否可用
torch.cuda.is_available()
# 返回 GPU 数量
torch.cuda.device_count()
# 返回 GPu 的名字，设备索引默认从 0 开始
torch.cuda.get_device_name(0)
# 返回当前设备索引
torch.cuda.current_device()
# 返回 torch 的版本
torch.__version__
# 返回 cuda 的版本
torch.version.cuda()
```

## 4. tensorflow 环境配置

`tensorflow` 与 `cuda`、`cudnn` 之间的适配关系参考：https://blog.csdn.net/oMoDao1/article/details/83241074

### 4.1 安装 tensorflow-gpu

```python
# 安装 GPU 版本的 tensorflow
pip install tensorflow-gpu
# 安装 CPU 版本的 tensorflow
pip install tensorflow
```

**注意： tensorflow的安装版本应该参考官方发布，与 cuda 的版本保持一致**

### 4.2 安装参考

- `tensorflow:` https://www.tensorflow.org/install#requirements_to_run_tensorflow_with_gpu_support
- `CUDA:` https://developer.nvidia.com/cuda-toolkit-archive

### 4.3 查看信息

```python
import tensorflow as tf
print(tf.__version__)   # tensorflow version
print(tf.__path__)      # tensorflow install path

```

## 5. Tips

### 5.1 查看 GPU 的使用情况

`nvidia-smi` 得到的信息比较少，这里使用 `gpustat`

详见 [gpustat](https://github.com/wookayin/gpustat)

### 5.2 `tmux` 的使用

项目地址 [tmux](https://github.com/tmux/tmux)，终端复用工具. 
命令参考：https://www.cnblogs.com/kaiye/p/6275207.html

tmux 中有几个比较重要的概念：

- session: 建立一个工作区会话
- window: 容纳多个窗格
- pane: 可以在窗格中分成多个窗格
- `ctrl + B` 基本指令，使用该指令之后，输入的下一个指令解释为 `tmux` 命令

1. 新建 session

    `tmux new -s name_xxx` name_xxx 为 session name

2. 一个 session 中新建 window

    `ctrl+B` -> `c`

    sesssion 中 window 之间的切换：  
     `ctrl+B` -> `n` 切换 next wiindow；  
     `ctrl+B` -> `p` 切换 previous window

3. 一个 window 里新建 pane

    左右切分 pane: `ctrl+B` -> `%`；  
    上下切分 pane: `ctrl+B` -> `"`；  
    pane 之间的切换使用 `ctrl+B` -> 上下左右；  
    关闭 pane: `ctrl+B` -> `x`
